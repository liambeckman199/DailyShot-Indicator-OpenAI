{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c6fb494",
   "metadata": {},
   "source": [
    "# OpenAI API Key\n",
    "\n",
    "This notebook requires access to OpenAI's GPT models, which need an API key. You can obtain the key from OpenAI's website. \n",
    "\n",
    "To use the key in this notebook, either set it as an environment variable named 'OPENAI_API_KEY' or modify the code to include it directly (not recommended for security reasons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff877455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import openai\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import yfinance as yf \n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d29c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc3abfe",
   "metadata": {},
   "source": [
    "## Scrape Data from DailyShot Webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee2af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_daily_shot_data(base_url, num_pages):\n",
    "    data = []\n",
    "\n",
    "    for page in range(1, num_pages + 1):\n",
    "        # Create the URL for the page\n",
    "        url = f'{base_url}page/{page}/'\n",
    "\n",
    "        response = requests.get(url)\n",
    "        html_content = response.text\n",
    "\n",
    "        # Parse the HTML with BeautifulSoup\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        entry_content_divs = soup.find_all('div', class_='entry-content')\n",
    "        entry_content_headers = soup.find_all('header', class_='entry-header')\n",
    "\n",
    "        for div, header in zip(entry_content_divs, entry_content_headers):\n",
    "            p_tags = div.find_all('p')\n",
    "            for p in p_tags:\n",
    "                text = p.get_text().strip()\n",
    "                if text and len(text.split()) > 5 and \"Contact the Daily Shot Editor\" not in text and \"Subscribe to the Daily Shot\" not in text:\n",
    "                    \n",
    "                    # Extract the date\n",
    "                    date_element = header.find('time', class_='entry-date')\n",
    "                    if date_element:\n",
    "                        date = date_element['datetime']\n",
    "                    else:\n",
    "                        date = None\n",
    "                    parts = text.split(': ', 1)\n",
    "                    if len(parts) == 2:\n",
    "                        title, content = parts\n",
    "                        # Only keep articles where Title is 'Equities'\n",
    "                        if title == 'Equities':  \n",
    "                            data.append({'Date': date, 'Title': title, 'Content': content})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e9cec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-11T15:45:09-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Broader US market performance would require st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-08T15:27:05-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>US stocks have outperformed international shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-06T15:29:31-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Share buybacks have accelerated, …</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-01T13:33:26-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>The Dow hit the highest level since early 2022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-29T15:12:41-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Long-only funds have been reducing their beta ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date     Title  \\\n",
       "0  2023-12-11T15:45:09-05:00  Equities   \n",
       "1  2023-12-08T15:27:05-05:00  Equities   \n",
       "2  2023-12-06T15:29:31-05:00  Equities   \n",
       "3  2023-12-01T13:33:26-05:00  Equities   \n",
       "4  2023-11-29T15:12:41-05:00  Equities   \n",
       "\n",
       "                                             Content  \n",
       "0  Broader US market performance would require st...  \n",
       "1  US stocks have outperformed international shar...  \n",
       "2                 Share buybacks have accelerated, …  \n",
       "3  The Dow hit the highest level since early 2022...  \n",
       "4  Long-only funds have been reducing their beta ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = extract_daily_shot_data('https://dailyshotbrief.com/',100)\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7116036",
   "metadata": {},
   "source": [
    "## Open AI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d731c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment_to_numeric(sentiment):\n",
    "    # Map text sentiment to numeric values\n",
    "    if 'Bullish' in sentiment:\n",
    "        return int(1)  \n",
    "    elif 'Bearish' in sentiment:\n",
    "        return int(0)  \n",
    "\n",
    "def classify_sentiment_openai(snippet):\n",
    "    # Initial prompt\n",
    "    primary_prompt = (f\"Classify the sentiment of this financial market snippet as either 'Bullish', 'Bearish', or 'Neutral':\\n\\n'{snippet}'\")\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        # Use best text LLM model\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=primary_prompt,\n",
    "        max_tokens=60,  \n",
    "        temperature=0.5,\n",
    "    )\n",
    "    \n",
    "    primary_response = response['choices'][0]['text'].strip()\n",
    "     # Handling Neutral responses with a second prompt\n",
    "    if primary_response == 'Neutral':\n",
    "        secondary_prompt = (f\"The sentiment of the snippet was classified as 'Neutral'. Please make a definitively classifcation between 'Bullish' and 'Bearish'. The response can only be 'Bullish' or 'Bearish', no exceptions:\\n\\n'{snippet}'\")\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",\n",
    "            prompt=secondary_prompt,\n",
    "            max_tokens=60,\n",
    "            temperature=0.5,\n",
    "        )\n",
    "        secondary_response = response['choices'][0]['text'].strip()\n",
    "        return map_sentiment_to_numeric(secondary_response)\n",
    "    \n",
    "    return map_sentiment_to_numeric(primary_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ba0cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Sentiment OpenAI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-11T15:45:09-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Broader US market performance would require st...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-08T15:27:05-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>US stocks have outperformed international shar...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-06T15:29:31-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Share buybacks have accelerated, …</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-01T13:33:26-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>The Dow hit the highest level since early 2022...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-29T15:12:41-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Long-only funds have been reducing their beta ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2022-12-21T14:49:14-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>No Santa rally this year.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2022-12-16T14:00:54-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Stocks tumbled on Thursday in response to the...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2022-12-15T10:34:58-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>The recession scenario could bring further pai...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2022-12-14T07:07:01-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>The S&amp;P 500 downtrend resistance held after th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2022-12-12T09:27:47-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>The market expects a volatile week. Here is th...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date     Title  \\\n",
       "0    2023-12-11T15:45:09-05:00  Equities   \n",
       "1    2023-12-08T15:27:05-05:00  Equities   \n",
       "2    2023-12-06T15:29:31-05:00  Equities   \n",
       "3    2023-12-01T13:33:26-05:00  Equities   \n",
       "4    2023-11-29T15:12:41-05:00  Equities   \n",
       "..                         ...       ...   \n",
       "150  2022-12-21T14:49:14-05:00  Equities   \n",
       "151  2022-12-16T14:00:54-05:00  Equities   \n",
       "152  2022-12-15T10:34:58-05:00  Equities   \n",
       "153  2022-12-14T07:07:01-05:00  Equities   \n",
       "154  2022-12-12T09:27:47-05:00  Equities   \n",
       "\n",
       "                                               Content  Sentiment OpenAI  \n",
       "0    Broader US market performance would require st...               1.0  \n",
       "1    US stocks have outperformed international shar...               1.0  \n",
       "2                   Share buybacks have accelerated, …               1.0  \n",
       "3    The Dow hit the highest level since early 2022...               1.0  \n",
       "4    Long-only funds have been reducing their beta ...               1.0  \n",
       "..                                                 ...               ...  \n",
       "150                          No Santa rally this year.               0.0  \n",
       "151   Stocks tumbled on Thursday in response to the...               0.0  \n",
       "152  The recession scenario could bring further pai...               0.0  \n",
       "153  The S&P 500 downtrend resistance held after th...               0.0  \n",
       "154  The market expects a volatile week. Here is th...               1.0  \n",
       "\n",
       "[155 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment OpenAI'] = df['Content'].apply(classify_sentiment_openai)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e23560",
   "metadata": {},
   "source": [
    "## FinancialBERT-Sentiment-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c96c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liambeckman/.pyenv/versions/3.10.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "def classify_sentiment(df):\n",
    "    # Pretrained FinancialBERT model\n",
    "    model_name = \"ahmedrachid/FinancialBERT-Sentiment-Analysis\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    # Modifying the model to have only two classes (Bearish and Bullish)\n",
    "    model.config.num_labels = 2\n",
    "    model.classifier = torch.nn.Linear(model.config.hidden_size, model.config.num_labels)\n",
    "\n",
    "    sentiment_predictions = []\n",
    "\n",
    "    for content in df['Content']:\n",
    "        inputs = tokenizer(content, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Get the predicted sentiment label (0: Bearish, 1: Bullish)\n",
    "        predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "        sentiment_predictions.append(predicted_label)\n",
    "\n",
    "    df['Sentiment FinancialBERT'] = sentiment_predictions\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5945555d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Sentiment OpenAI</th>\n",
       "      <th>Sentiment FinancialBERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-11T15:45:09-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Broader US market performance would require st...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-08T15:27:05-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>US stocks have outperformed international shar...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-06T15:29:31-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Share buybacks have accelerated, …</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-01T13:33:26-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>The Dow hit the highest level since early 2022...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-29T15:12:41-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Long-only funds have been reducing their beta ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-28T12:30:56-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Here are sector earnings growth expectations f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-11-22T13:41:14-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Goldman expects share buybacks to drive net eq...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-11-17T13:51:05-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Analysts continue to downgrade their Q4 earnin...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-11-16T15:39:11-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>Bullish options bets on small caps are hitting...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-11-14T14:48:06-05:00</td>\n",
       "      <td>Equities</td>\n",
       "      <td>The earnings revision breadth has worsened for...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date     Title  \\\n",
       "0  2023-12-11T15:45:09-05:00  Equities   \n",
       "1  2023-12-08T15:27:05-05:00  Equities   \n",
       "2  2023-12-06T15:29:31-05:00  Equities   \n",
       "3  2023-12-01T13:33:26-05:00  Equities   \n",
       "4  2023-11-29T15:12:41-05:00  Equities   \n",
       "5  2023-11-28T12:30:56-05:00  Equities   \n",
       "6  2023-11-22T13:41:14-05:00  Equities   \n",
       "7  2023-11-17T13:51:05-05:00  Equities   \n",
       "8  2023-11-16T15:39:11-05:00  Equities   \n",
       "9  2023-11-14T14:48:06-05:00  Equities   \n",
       "\n",
       "                                             Content  Sentiment OpenAI  \\\n",
       "0  Broader US market performance would require st...               1.0   \n",
       "1  US stocks have outperformed international shar...               1.0   \n",
       "2                 Share buybacks have accelerated, …               1.0   \n",
       "3  The Dow hit the highest level since early 2022...               1.0   \n",
       "4  Long-only funds have been reducing their beta ...               1.0   \n",
       "5  Here are sector earnings growth expectations f...               1.0   \n",
       "6  Goldman expects share buybacks to drive net eq...               1.0   \n",
       "7  Analysts continue to downgrade their Q4 earnin...               0.0   \n",
       "8  Bullish options bets on small caps are hitting...               1.0   \n",
       "9  The earnings revision breadth has worsened for...               0.0   \n",
       "\n",
       "   Sentiment FinancialBERT  \n",
       "0                        1  \n",
       "1                        0  \n",
       "2                        1  \n",
       "3                        0  \n",
       "4                        1  \n",
       "5                        0  \n",
       "6                        1  \n",
       "7                        0  \n",
       "8                        0  \n",
       "9                        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=classify_sentiment(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356b6ed",
   "metadata": {},
   "source": [
    "## Calculate Average Sentiment in Time Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d689a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_sentiment(df, days, model):\n",
    "    # Convert the Date column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    start_dates = []\n",
    "    end_dates = []\n",
    "    sentiment_modes = []\n",
    "\n",
    "    # Calculate the number of days to shift for mode calculation\n",
    "    mode_shift = pd.DateOffset(days=days)\n",
    "\n",
    "    # Calculate the start and end date for the dataset\n",
    "    start_date = df['Date'].max()\n",
    "    end_date = df['Date'].min()\n",
    "\n",
    "    # Loop through entire dataset\n",
    "    while start_date >= end_date:\n",
    "        # Calculate the end date of the current time window\n",
    "        end_interval = start_date - mode_shift\n",
    "\n",
    "        interval_df = df[(df['Date'] >= end_interval) & (df['Date'] <= start_date)]\n",
    "\n",
    "        if not interval_df.empty:\n",
    "            start_dates.append(end_interval)\n",
    "            end_dates.append(start_date)\n",
    "\n",
    "            # Calculate the mode\n",
    "            sentiment_mode = interval_df[model].mode()\n",
    "            if not sentiment_mode.empty:\n",
    "                sentiment_modes.append(sentiment_mode.iloc[0])\n",
    "            else:\n",
    "                sentiment_modes.append(None)\n",
    "\n",
    "        #Shift end date by window\n",
    "        start_date -= mode_shift\n",
    "\n",
    "    aggregated_df = pd.DataFrame({\n",
    "        'start_date': start_dates,\n",
    "        'end_date': end_dates,\n",
    "        'Sentiment': sentiment_modes\n",
    "    })\n",
    "\n",
    "    return aggregated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c32fe82e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-04 15:45:09-05:00</td>\n",
       "      <td>2023-12-11 15:45:09-05:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-27 15:45:09-05:00</td>\n",
       "      <td>2023-12-04 15:45:09-05:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-20 15:45:09-05:00</td>\n",
       "      <td>2023-11-27 15:45:09-05:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-13 15:45:09-05:00</td>\n",
       "      <td>2023-11-20 15:45:09-05:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-06 15:45:09-05:00</td>\n",
       "      <td>2023-11-13 15:45:09-05:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 start_date                  end_date  Sentiment\n",
       "0 2023-12-04 15:45:09-05:00 2023-12-11 15:45:09-05:00        1.0\n",
       "1 2023-11-27 15:45:09-05:00 2023-12-04 15:45:09-05:00        1.0\n",
       "2 2023-11-20 15:45:09-05:00 2023-11-27 15:45:09-05:00        1.0\n",
       "3 2023-11-13 15:45:09-05:00 2023-11-20 15:45:09-05:00        0.0\n",
       "4 2023-11-06 15:45:09-05:00 2023-11-13 15:45:09-05:00        1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_df=calculate_average_sentiment(df,7,'Sentiment OpenAI')\n",
    "aggregated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884c839",
   "metadata": {},
   "source": [
    "## Yfinance to fetch Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68724510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sp500_data(start_date, end_date):\n",
    "    # Fetch S&P 500 data\n",
    "    sp500_data = yf.download('^GSPC', start=start_date, end=end_date)\n",
    "    return sp500_data\n",
    "\n",
    "def calculate_average_sp500_return(df):\n",
    "    average_returns = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        start_date = row['start_date']\n",
    "        end_date = row['end_date']\n",
    "\n",
    "        # Fetch S&P 500 data for the date range\n",
    "        sp500_data = fetch_sp500_data(start_date, end_date)\n",
    "\n",
    "        # Calculate the average return using Adj Close \n",
    "        average_return = sp500_data['Adj Close'].pct_change().mean() * 100 \n",
    "        average_returns.append(average_return)\n",
    "\n",
    "    df['Average SP500 Return (%)'] = average_returns\n",
    "    \n",
    "    df['Positive or Negative Return'] = df['Average SP500 Return (%)'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # Shift the Average SP500 Return, assuming the current SP500 Return does not correlate to current news sentiment\n",
    "\n",
    "    df['Positive or Negative Return Lookback 1 Weeks'] = df['Positive or Negative Return'].shift(1)\n",
    "    \n",
    "    df['Positive or Negative Return Lookback 2 Weeks'] = df['Positive or Negative Return'].shift(2)\n",
    "    \n",
    "    df['Positive or Negative Return Lookback 3 Weeks'] = df['Positive or Negative Return'].shift(3)\n",
    "    \n",
    "    df['Positive or Negative Return Lookback 4 Weeks'] = df['Positive or Negative Return'].shift(4)\n",
    "    \n",
    "    df['Positive or Negative Return Lookback -1 Weeks'] = df['Positive or Negative Return'].shift(-1)\n",
    "    \n",
    "    df['Positive or Negative Return Lookback -2 Weeks'] = df['Positive or Negative Return'].shift(-2)\n",
    "    \n",
    "    df['Positive or Negative Return Lookback -3 Weeks'] = df['Positive or Negative Return'].shift(-3)\n",
    "    \n",
    "    df['Positive or Negative Return Lookback -4 Weeks'] = df['Positive or Negative Return'].shift(-4)\n",
    "\n",
    "    df = df.iloc[:-1]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecbe541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Average SP500 Return (%)</th>\n",
       "      <th>Positive or Negative Return</th>\n",
       "      <th>Positive or Negative Return Lookback 1 Weeks</th>\n",
       "      <th>Positive or Negative Return Lookback 2 Weeks</th>\n",
       "      <th>Positive or Negative Return Lookback 3 Weeks</th>\n",
       "      <th>Positive or Negative Return Lookback 4 Weeks</th>\n",
       "      <th>Positive or Negative Return Lookback -1 Weeks</th>\n",
       "      <th>Positive or Negative Return Lookback -2 Weeks</th>\n",
       "      <th>Positive or Negative Return Lookback -3 Weeks</th>\n",
       "      <th>Positive or Negative Return Lookback -4 Weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-04 15:45:09-05:00</td>\n",
       "      <td>2023-12-11 15:45:09-05:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230262</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-27 15:45:09-05:00</td>\n",
       "      <td>2023-12-04 15:45:09-05:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.085664</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-20 15:45:09-05:00</td>\n",
       "      <td>2023-11-27 15:45:09-05:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-13 15:45:09-05:00</td>\n",
       "      <td>2023-11-20 15:45:09-05:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.610696</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-06 15:45:09-05:00</td>\n",
       "      <td>2023-11-13 15:45:09-05:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.210836</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 start_date                  end_date  Sentiment  \\\n",
       "0 2023-12-04 15:45:09-05:00 2023-12-11 15:45:09-05:00        1.0   \n",
       "1 2023-11-27 15:45:09-05:00 2023-12-04 15:45:09-05:00        1.0   \n",
       "2 2023-11-20 15:45:09-05:00 2023-11-27 15:45:09-05:00        1.0   \n",
       "3 2023-11-13 15:45:09-05:00 2023-11-20 15:45:09-05:00        0.0   \n",
       "4 2023-11-06 15:45:09-05:00 2023-11-13 15:45:09-05:00        1.0   \n",
       "\n",
       "   Average SP500 Return (%)  Positive or Negative Return  \\\n",
       "0                  0.230262                            1   \n",
       "1                  0.085664                            1   \n",
       "2                  0.017073                            1   \n",
       "3                  0.610696                            1   \n",
       "4                  0.210836                            1   \n",
       "\n",
       "   Positive or Negative Return Lookback 1 Weeks  \\\n",
       "0                                           NaN   \n",
       "1                                           1.0   \n",
       "2                                           1.0   \n",
       "3                                           1.0   \n",
       "4                                           1.0   \n",
       "\n",
       "   Positive or Negative Return Lookback 2 Weeks  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           1.0   \n",
       "3                                           1.0   \n",
       "4                                           1.0   \n",
       "\n",
       "   Positive or Negative Return Lookback 3 Weeks  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           1.0   \n",
       "4                                           1.0   \n",
       "\n",
       "   Positive or Negative Return Lookback 4 Weeks  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           1.0   \n",
       "\n",
       "   Positive or Negative Return Lookback -1 Weeks  \\\n",
       "0                                            1.0   \n",
       "1                                            1.0   \n",
       "2                                            1.0   \n",
       "3                                            1.0   \n",
       "4                                            1.0   \n",
       "\n",
       "   Positive or Negative Return Lookback -2 Weeks  \\\n",
       "0                                            1.0   \n",
       "1                                            1.0   \n",
       "2                                            1.0   \n",
       "3                                            1.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   Positive or Negative Return Lookback -3 Weeks  \\\n",
       "0                                            1.0   \n",
       "1                                            1.0   \n",
       "2                                            1.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   Positive or Negative Return Lookback -4 Weeks  \n",
       "0                                            1.0  \n",
       "1                                            1.0  \n",
       "2                                            0.0  \n",
       "3                                            0.0  \n",
       "4                                            1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_df=calculate_average_sp500_return(aggregated_df)\n",
    "aggregated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae11cb2a",
   "metadata": {},
   "source": [
    "## Evaluating the correlation of sentiment to market returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e89cd2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy_f1(df):\n",
    "    result_df = pd.DataFrame(columns=['accuracy', 'f1_score'], \n",
    "                             index=['Lookback 1 Weeks', 'Lookback 2 Weeks', 'Lookback 3 Weeks', 'Lookback 4 Weeks',\n",
    "                                   'Lookback -1 Weeks','Lookback -2 Weeks','Lookback -3 Weeks','Lookback -4 Weeks'])\n",
    "\n",
    "    # Forward Shifting\n",
    "    for lookback_period in range(1, 5):\n",
    "        # Calculate accuracy and F1 score for the current lookback window\n",
    "        column_name = f'Positive or Negative Return Lookback {lookback_period} Weeks' \n",
    "        y_true = df['Sentiment']\n",
    "        y_pred = df[column_name]\n",
    "        \n",
    "        # Remove rows with NaN values\n",
    "        valid_indices = ~np.isnan(y_pred)  \n",
    "        y_true = y_true[valid_indices]\n",
    "        y_pred = y_pred[valid_indices]\n",
    "        \n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        \n",
    "        result_df.loc[f'Lookback {lookback_period} Weeks'] = [accuracy, f1]\n",
    "        \n",
    "    # Backward Shifting\n",
    "    for lookback_period in range(-1, -5, -1):\n",
    "        column_name = f'Positive or Negative Return Lookback {lookback_period} Weeks' \n",
    "        y_true = df['Sentiment']\n",
    "        y_pred = df[column_name]\n",
    "        \n",
    "        # Remove rows with NaN values\n",
    "        valid_indices = ~np.isnan(y_pred)  \n",
    "        y_true = y_true[valid_indices]\n",
    "        y_pred = y_pred[valid_indices]\n",
    "        \n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        \n",
    "        result_df.loc[f'Lookback {lookback_period} Weeks'] = [accuracy, f1]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8443ac5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lookback 1 Weeks</th>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.606161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lookback 2 Weeks</th>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.55531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lookback 3 Weeks</th>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.372353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lookback 4 Weeks</th>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.515638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lookback -1 Weeks</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.577016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lookback -2 Weeks</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.427253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lookback -3 Weeks</th>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.563784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lookback -4 Weeks</th>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.638607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   accuracy  f1_score\n",
       "Lookback 1 Weeks   0.604167  0.606161\n",
       "Lookback 2 Weeks   0.553191   0.55531\n",
       "Lookback 3 Weeks   0.369565  0.372353\n",
       "Lookback 4 Weeks   0.511111  0.515638\n",
       "Lookback -1 Weeks  0.571429  0.577016\n",
       "Lookback -2 Weeks  0.416667  0.427253\n",
       "Lookback -3 Weeks  0.553191  0.563784\n",
       "Lookback -4 Weeks  0.630435  0.638607"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resuls_df = calculate_accuracy_f1(aggregated_df)\n",
    "resuls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beb6439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
